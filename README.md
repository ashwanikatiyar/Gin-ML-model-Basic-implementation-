Here is the complete text formatted as a clean, ready-to-use Markdown (`.md`) file. I've cleaned up the structure, properly nested the code blocks, and formatted the math using standard LaTeX for GitHub-style rendering.

```markdown
# ğŸ§  Sentiment Analysis API (ML from Scratch in Go)

A lightweight **Sentiment Analysis REST API** built using **Go (Gin)** with a **Logistic Regression model implemented from scratch** (no ML libraries).

This project demonstrates how to design, train, and serve a simple machine learning model as a backend service, with a clear separation between **ML logic** and **API infrastructure**.

---

## âœ¨ Features

- ğŸš€ **REST API** built with Gin
- ğŸ§® **Logistic Regression** implemented from scratch
- ğŸ“ **Simple Bag-of-Words** text vectorization
- ğŸ” **Clear separation** of training and prediction
- ğŸ“¦ **No ML frameworks** (no sklearn, no TensorFlow)
- ğŸ§  **Fully explainable** and interpretable model

---

## ğŸ“Œ Problem Statement

Given a short piece of text, predict whether its sentiment is:
- **Positive**
- **Negative**

The model outputs:
- A probability score (`0.0 â€“ 1.0`)
- A sentiment label based on the score

---

## ğŸ—ï¸ Project Structure

```text
sentiment-api/
â”‚
â”œâ”€â”€ main.go            # Gin server entry point
â”œâ”€â”€ go.mod
â”‚
â”œâ”€â”€ api/
â”‚   â””â”€â”€ handlers.go    # HTTP request handlers
â”‚
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ vectorizer.go  # Bag-of-Words implementation
â”‚   â”œâ”€â”€ model.go       # Logistic Regression model
â”‚   â”œâ”€â”€ train.go       # Gradient Descent training
â”‚   â””â”€â”€ state.go       # In-memory model state
â”‚
â””â”€â”€ README.md

```

---

## ğŸ§  Machine Learning Details

### Model

* **Logistic Regression**: Binary classification (positive / negative).

### Text Vectorization

* **Bag-of-Words**:
* Vocabulary learned from training data.
* Text converted into numeric feature vectors.



### Training

* **Loss Function**: Binary Cross-Entropy.
* **Optimization**: Gradient Descent.
* Weights and bias updated iteratively.

### ğŸ”¢ Logistic Regression Model

The predicted output is calculated using the **Sigmoid Activation Function**, which converts the linear combination of inputs into a probability score:

$$\hat{y} = \sigma(w \cdot x + b)$$

**Where:**

* **$x$**: The input text feature vector (e.g., Bag-of-Words).
* **$w$**: The learned weights that determine the importance of each feature.
* **$b$**: The bias term (intercept).
* **$\sigma$**: The Sigmoid function, defined as $\sigma(z) = \frac{1}{1 + e^{-z}}$, which maps any real-valued number into a probability between $0$ and $1$.
---

## ğŸŒ API Endpoints

### 1ï¸âƒ£ Health Check

`GET /health`

**Response:**

```json
{
  "status": "ok"
}

```

### 2ï¸âƒ£ Train Model

`POST /train`

Trains the model using labeled text data.

**Request:**

```json
{
  "data": [
    { "text": "I love this product", "label": 1 },
    { "text": "This is terrible", "label": 0 }
  ]
}

```

**Response:**

```json
{
  "message": "model trained successfully",
  "vocab": 6
}

```

> ğŸ“Œ **Note:** Training updates the in-memory model state.

### 3ï¸âƒ£ Predict Sentiment

`POST /predict`

**Request:**

```json
{
  "text": "I really love this"
}

```

**Response:**

```json
{
  "text": "I really love this",
  "probability": 0.94,
  "sentiment": "positive"
}

```

---

## ğŸš€ Getting Started

### Prerequisites

* Go 1.20+
* macOS / Linux / Windows

### Run the Server

1. Initialize the module:
```bash
go mod init sentiment-api
go mod tidy

```


2. Start the application:
```bash
go run main.go

```


3. Server starts on: `http://localhost:8080`

---

## ğŸ§ª Example Usage (curl)

### Train

```bash
curl -X POST http://localhost:8080/train \
-H "Content-Type: application/json" \
-d '{
  "data": [
    {"text": "I love this", "label": 1},
    {"text": "This is great", "label": 1},
    {"text": "I hate this", "label": 0},
    {"text": "This is terrible", "label": 0}
  ]
}'

```

### Predict

```bash
curl -X POST http://localhost:8080/predict \
-H "Content-Type: application/json" \
-d '{ "text": "I love this product" }'

```

---

## âš ï¸ Limitations (By Design)

* Model is **in-memory only** (state is lost on server restart).
* No persistence or model versioning.
* Simple Bag-of-Words (no deep embeddings like BERT).
* Intended for learning, not high-scale production use.

---

## ğŸ§  What This Project Demonstrates

* How ML models work internally (**no black boxes**).
* How to integrate ML with **backend APIs**.
* Separation of **training** and **inference**.
* Practical ML engineering thinking.
* Clean, minimal Go backend design.

---

## ğŸ”® Possible Improvements

* Persist model to disk or object storage.
* Separate trainer and serving services.
* Add evaluation metrics (accuracy, precision).
* Support larger datasets.
* Dockerize the service.

---

## ğŸ‘¨â€ğŸ’» Author

Built as a learning-focused ML + backend engineering project using **Go** and **Gin**.

```

```